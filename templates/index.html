<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Companion</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        'sans': ['Inter', 'ui-sans-serif', 'system-ui'],
                    },
                    keyframes: {
                        fadeIn: {
                            '0%': { opacity: '0', transform: 'translateY(10px)' },
                            '100%': { opacity: '1', transform: 'translateY(0)' },
                        },
                        pulse: {
                            '0%, 100%': { transform: 'scale(1)' },
                            '50%': { transform: 'scale(1.05)' },
                        }
                    },
                    animation: {
                        'fade-in': 'fadeIn 0.5s ease-out',
                        'pulse-soft': 'pulse 2s ease-in-out infinite'
                    }
                }
            }
        }
    </script>
    <style>
        .mic-icon {
            animation: pulse 2s ease-in-out infinite;
        }
        .glass-morphism {
            background: rgba(255, 255, 255, 0.7);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
    </style>
</head>
<body class="bg-gradient-to-br from-blue-50 to-indigo-100 min-h-screen flex flex-col">
    <div class="container mx-auto px-4 py-8 max-w-2xl flex-grow">
        <div class="bg-white/80 glass-morphism shadow-2xl rounded-3xl p-8 md:p-12 border border-white/20 transform transition-all hover:scale-[1.02]">
            <div class="flex items-center justify-center mb-8">
                <i class="fas fa-microphone-alt text-4xl text-blue-600 mr-4 mic-icon"></i>
                <h1 class="text-4xl md:text-5xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-blue-600 to-indigo-600">
                    AI Voice Companion
                </h1>
            </div>

            <div class="mb-8 text-center">
                <p id="status" class="text-lg text-gray-600 min-h-[2rem] italic">
                    <i class="fas fa-info-circle mr-2"></i>Click "Start Recording" to begin your conversation
                </p>
            </div>

            <div class="flex flex-col space-y-6">
                <!-- Recording Controls -->
                <div class="flex justify-center space-x-6">
                    <button id="start-recording"
                            class="flex items-center space-x-2 bg-gradient-to-r from-blue-500 to-indigo-600 text-white px-8 py-4 rounded-full hover:from-blue-600 hover:to-indigo-700 transition-all duration-300 transform hover:scale-105 focus:outline-none focus:ring-4 focus:ring-blue-300 focus:ring-opacity-50 shadow-lg hover:shadow-xl">
                        <i class="fas fa-play mr-2"></i>
                        Start Recording
                    </button>
                    <button id="stop-recording"
                            disabled
                            class="flex items-center space-x-2 bg-gradient-to-r from-red-500 to-pink-600 text-white px-8 py-4 rounded-full hover:from-red-600 hover:to-pink-700 transition-all duration-300 transform hover:scale-105 disabled:opacity-50 disabled:cursor-not-allowed disabled:hover:scale-100 shadow-lg hover:shadow-xl">
                        <i class="fas fa-stop mr-2"></i>
                        Stop Recording
                    </button>
                </div>

                <!-- Hidden Audio Players -->
                <audio id="audio-player" style="display:none;"></audio>
                <audio id="tts-audio-player" style="display:none;"></audio>

                <!-- Transcription Result -->
                <div id="transcription-result" class="hidden animate-fade-in">
                    <div class="bg-white/60 glass-morphism rounded-2xl p-6 border border-white/20 shadow-lg">
                        <div class="flex items-center mb-4">
                            <i class="fas fa-comment-dots text-blue-600 mr-3 text-2xl"></i>
                            <h2 class="text-xl font-semibold text-gray-800">Transcription</h2>
                        </div>
                        <p id="transcription-text" class="text-gray-700 mb-6 bg-gray-100 p-4 rounded-lg"></p>

                        <div class="flex items-center mb-4">
                            <i class="fas fa-robot text-green-600 mr-3 text-2xl"></i>
                            <h2 class="text-xl font-semibold text-gray-800">AI Response</h2>
                        </div>
                        <p id="ai-response-text" class="text-gray-700 bg-gray-100 p-4 rounded-lg"></p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <footer class="bg-white/60 glass-morphism py-6 mt-6 border-t border-white/20">
        <div class="container mx-auto text-center text-gray-600 flex items-center justify-center">
            <i class="fas fa-heart text-red-500 mr-2"></i>
            © 2024 AI Voice Companion
            <i class="fas fa-heart text-red-500 ml-2"></i>
        </div>
    <footer class="bg-white py-4 mt-6">
        <div class="container mx-auto text-center text-gray-600">
            © 2024 AI Voice Companion
        </div>
    </footer>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let stream;

        const startButton = document.getElementById("start-recording");
        const stopButton = document.getElementById("stop-recording");
        const statusText = document.getElementById("status");
        const audioPlayer = document.getElementById("audio-player");
        const ttsAudioPlayer = document.getElementById("tts-audio-player");
        const transcriptionResult = document.getElementById("transcription-result");
        const transcriptionText = document.getElementById("transcription-text");
        const aiResponseText = document.getElementById("ai-response-text");

        async function startRecording() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        channelCount: 1,
                        sampleRate: 44100
                    }
                });

                const mimeType = MediaRecorder.isTypeSupported('audio/wav')
                    ? 'audio/wav'
                    : 'audio/webm';

                mediaRecorder = new MediaRecorder(stream, { mimeType });
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstart = () => {
                    statusText.textContent = "Recording...";
                    startButton.disabled = true;
                    stopButton.disabled = false;
                };

                mediaRecorder.onstop = () => {
                    stream.getTracks().forEach(track => track.stop());

                    if (audioChunks.length === 0) {
                        statusText.textContent = "No audio recorded. Please try again.";
                        return;
                    }

                    const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType });
                    const audioURL = URL.createObjectURL(audioBlob);

                    audioPlayer.src = audioURL;
                    statusText.textContent = "Recording stopped. Uploading...";
                    uploadRecording(audioBlob);
                };

                mediaRecorder.start();
            } catch (error) {
                statusText.textContent = `Microphone access error: ${error.message}`;
                console.error("Recording error:", error);
            }
        }

        async function uploadRecording(audioBlob) {
            const formData = new FormData();
            formData.append("audio", audioBlob, `recording.${audioBlob.type.split('/')[1]}`);

            statusText.textContent = "Uploading audio for transcription...";
            try {
                const response = await fetch("/transcribe", {
                    method: "POST",
                    body: formData
                });

                if (response.ok) {
                    const result = await response.json();
                    transcriptionText.textContent = result.transcription;
                    aiResponseText.textContent = result.ai_response;
                    transcriptionResult.style.display = "block";

                    // Automatically play both audio files
                    if (result.tts_audio) {
                        ttsAudioPlayer.src = result.tts_audio;

                        // Play original audio first
                        audioPlayer.onended = () => {
                            // Then play TTS audio
                            ttsAudioPlayer.play();
                        };
                        audioPlayer.play();
                    }

                    statusText.textContent = "Transcription complete. Playing audio...";
                } else {
                    const error = await response.text();
                    transcriptionText.textContent = `Server Error: ${error}`;
                    transcriptionResult.style.display = "block";
                    statusText.textContent = "Transcription failed.";
                }
            } catch (error) {
                transcriptionText.textContent = `Error: ${error.message}`;
                transcriptionResult.style.display = "block";
                statusText.textContent = "Transcription failed.";
                console.error("Upload error:", error);
            }
        }

        startButton.addEventListener("click", startRecording);

        stopButton.addEventListener("click", () => {
            if (mediaRecorder && mediaRecorder.state === "recording") {
                mediaRecorder.stop();
                stopButton.disabled = true;
            } else {
                statusText.textContent = "No active recording to stop.";
            }
        });

        // Check browser support
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            statusText.textContent = "Your browser does not support audio recording.";
            startButton.disabled = true;
        }
    </script>
</body>
</html>